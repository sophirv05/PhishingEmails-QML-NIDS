{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e3e8c7",
   "metadata": {},
   "source": [
    "# Detecting network intrusions & anomalies with higher-order topological kernels via quantum computation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfac267-82fe-4f73-88c5-6ea6189b30a7",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec175ffc",
   "metadata": {},
   "source": [
    "0.0. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10e184aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from quask.core_implementation.qiskit_kernel import QiskitKernel\n",
    "from quask.core import KernelType, Ansatz, KernelFactory\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler   # added\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcc566",
   "metadata": {},
   "source": [
    "0.1. Establish creds if running on IBM hardware (assumes IBM Quantum Cloud account exists and credentials saved with save_account())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f0261e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Qiskit simulator (noiseless mode).\n"
     ]
    }
   ],
   "source": [
    "# service = QiskitRuntimeService(instance=\"crn:v1:bluemix:public:quantum-computing:us-east:a/b8ff6077c08a4ea9871560ccb827d457:d3452110-b228-4c79-8959-15ea8cfd435d::\") # assuming creds saved with save_account()\n",
    "# backend = service.backend(\"ibm_rensselaer\")\n",
    "print(\"Running on Qiskit simulator (noiseless mode).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3627f80f-dde7-464b-8423-860f4e15b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… qiskit imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from qiskit_aer import Aer\n",
    "\n",
    "print(\"âœ… qiskit imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352fb4b",
   "metadata": {},
   "source": [
    "## 1. Create Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fed2ca",
   "metadata": {},
   "source": [
    "### 1.0. Configure for either quantum simulator or hardware backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e690ed",
   "metadata": {},
   "source": [
    "Simulator (noiseless) backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dffc0157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelFactory set to Qiskit noiseless simulator.\n"
     ]
    }
   ],
   "source": [
    "def create_qiskit_noiseless(ansatz, measurement: str, type: KernelType):\n",
    "    return QiskitKernel(\n",
    "        ansatz,\n",
    "        measurement,\n",
    "        type,\n",
    "        platform=\"Aer\",\n",
    "        n_shots=None\n",
    "    )\n",
    "\n",
    "try:\n",
    "    KernelFactory.add_implementation('qiskit_noiseless', create_qiskit_noiseless)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "KernelFactory.set_current_implementation('qiskit_noiseless')\n",
    "print(\"KernelFactory set to Qiskit noiseless simulator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f6828",
   "metadata": {},
   "source": [
    "Hardware (NISQ) backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af2a7e",
   "metadata": {},
   "source": [
    "Note: only one implementation can be selected (e.g., qiskit_noiseless OR qiskit_ibm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07051ffa-bf6e-46d1-8f76-b00088dbe698",
   "metadata": {},
   "source": [
    "### 1.1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af0733b3-0b99-447e-b30e-772670dbf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded datasets: (500, 5) (500, 5)\n"
     ]
    }
   ],
   "source": [
    "benign_path = \"500-benign.npy\"\n",
    "attack_path = \"500-attack.npy\"\n",
    "\n",
    "qX1 = np.load(benign_path)\n",
    "qX2 = np.load(attack_path)\n",
    "\n",
    "attack_name = os.path.basename(attack_path).replace(\"attack\", \"\").replace(\".npy\", \"\").upper()\n",
    "\n",
    "print(\"âœ… Loaded datasets:\", qX1.shape, qX2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c87f6ea8-ef23-4c22-a6a4-519775d1f3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Number of features: 5\n"
     ]
    }
   ],
   "source": [
    "n_features = qX1.shape[1]\n",
    "print(\"âœ… Number of features:\", n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd86ac-3a3b-4833-a546-8d47184c5867",
   "metadata": {},
   "source": [
    "### 1.2. Build Quantum Ansatz & Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1f803",
   "metadata": {},
   "source": [
    "Config modified from QuASK iris dataset anomaly detection example; see [QuASK: How to optimize a quantum kernel](https://quask.readthedocs.io/en/latest/tutorials_quask/quask_2_optimizers.html) for alternate optimization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f7aa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = Ansatz(n_features=n_features, n_qubits=4, n_operations=4)\n",
    "ansatz.initialize_to_identity()\n",
    "\n",
    "ansatz.change_operation(0, 0, [0,1], \"XX\", 3.0)\n",
    "ansatz.change_operation(1, 1, [1,2], \"XY\", 3.0)\n",
    "ansatz.change_operation(2, 2, [2,3], \"XZ\", 3.0)\n",
    "ansatz.change_operation(3, 3, [3,0], \"YY\", 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85bf7a7f-b221-4582-bbe9-fb59cd05db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kernel built successfully!\n"
     ]
    }
   ],
   "source": [
    "kernel = KernelFactory.create_kernel(ansatz, \"ZZZZ\", KernelType.FIDELITY)\n",
    "print(\"âœ… Kernel built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f06468",
   "metadata": {},
   "source": [
    "### 1.2. Instantiate machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b04308dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SVM upgraded.\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='precomputed', C=10, class_weight='balanced')  # CHANGED\n",
    "print(\"âœ… SVM upgraded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c54c3e",
   "metadata": {},
   "source": [
    "## 2. Fit quantum kernels to SVM model and test on BCCC-CIC-CSE-IDS2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd6ea8e",
   "metadata": {},
   "source": [
    "2.0. Load modified datasets (see KERNELSCRIPT.py for dataset cleaning and reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17081189",
   "metadata": {},
   "source": [
    "2.1. Create testing and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e24d0706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data split.\n"
     ]
    }
   ],
   "source": [
    "qX1 = qX1[:50]   # âœ… CHANGE TO 30, 50, 80, 100 to experiment\n",
    "qX2 = qX2[:50]\n",
    "\n",
    "qX = np.vstack([qX1, qX2])\n",
    "qy = np.array([-1]*len(qX1) + [1]*len(qX2))\n",
    "\n",
    "qX_train, qX_test, qy_train, qy_test = train_test_split(\n",
    "    qX, qy, test_size=0.3, random_state=42, stratify=qy   # âœ… ADDED stratify\n",
    ")\n",
    "\n",
    "print(\"âœ… Data split.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab245fd3",
   "metadata": {},
   "source": [
    "2.2. Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "650d1e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data standardized.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()   # âœ… CHANGED\n",
    "samples = np.append(qX_train, qX_test, axis=0)\n",
    "scaler.fit(samples)\n",
    "\n",
    "qX_train = scaler.transform(qX_train)\n",
    "qX_test = scaler.transform(qX_test)\n",
    "\n",
    "print(\"âœ… Data standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39f2ba",
   "metadata": {},
   "source": [
    "### 2.3. Build training matrix using quantum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1964c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model trained.\n"
     ]
    }
   ],
   "source": [
    "K_train = kernel.build_kernel(qX_train, qX_train)\n",
    "model.fit(K_train, qy_train)\n",
    "print(\"âœ… Model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592766c",
   "metadata": {},
   "source": [
    "### 2.4. Predict the labels for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be2a8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test data\n",
    "K_test = kernel.build_kernel(qX_test, qX_train)\n",
    "y_pred = model.predict(K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae815913",
   "metadata": {},
   "source": [
    "### 2.5. Calculate and output QML model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d4f54e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 500- is 0.7\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(qy_test == y_pred) / len(qy_test)\n",
    "print(\"ðŸŽ¯ BASELINE ACCURACY:\", accuracy)\n",
    "\n",
    "# Optional additional metrics\n",
    "# from sklearn.metrics import classification_report\n",
    "# cr = classification_report(qy_test, y_pred)\n",
    "# print(cr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f50a8",
   "metadata": {},
   "source": [
    "## 3. Further notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d3fbc",
   "metadata": {},
   "source": [
    "The above demo handles a singular network attack, split for improved readability. Below is our testing across all attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b609b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy for -: 0.722\n"
     ]
    }
   ],
   "source": [
    "data_dir = '.'\n",
    "\n",
    "for fname in os.listdir(data_dir):\n",
    "    if fname.endswith('.npy') and 'benign' in fname:\n",
    "        benign_path = os.path.join(data_dir, fname)\n",
    "        \n",
    "        # Construct corresponding attack file name\n",
    "        attack_fname = fname.replace('benign', 'attack')\n",
    "        attack_path = os.path.join(data_dir, attack_fname)\n",
    "\n",
    "        attack_label = attack_fname.replace(\"attack\", \"\").replace(\"500\", \"\").replace(\".npy\", \"\").upper()\n",
    "\n",
    "        if os.path.exists(attack_path):\n",
    "            # Load both arrays\n",
    "            qX1 = np.load(benign_path)\n",
    "            qX2 = np.load(attack_path)\n",
    "\n",
    "            # select first 30 samples\n",
    "            qX1 = qX1[:30]\n",
    "            qX2 = qX2[:30]\n",
    "\n",
    "            # Create testing/training sets\n",
    "            qX = np.vstack([qX1, qX2])\n",
    "            qy = np.array([-1] * len(qX1) + [1] * len(qX2))\n",
    "\n",
    "            qX_train, qX_test, qy_train, qy_test = train_test_split(\n",
    "                qX, qy, test_size=0.3, random_state=42\n",
    "            )\n",
    "            \n",
    "            # normalize data\n",
    "            samples = np.append(qX_train, qX_test, axis=0)\n",
    "            minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
    "            qX_train = minmax_scale.transform(qX_train)\n",
    "            qX_test = minmax_scale.transform(qX_test)\n",
    "\n",
    "            # Train\n",
    "            K_train = kernel.build_kernel(qX_train, qX_train)\n",
    "            model.fit(K_train, qy_train)\n",
    "        \n",
    "            # Test\n",
    "            K_test = kernel.build_kernel(qX_test, qX_train)\n",
    "            y_pred = model.predict(K_test)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = np.mean(qy_test == y_pred)\n",
    "            print(f\"âœ… Accuracy for {attack_label}: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f2c5f-9864-4809-aff6-4bb330b9ba57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qml-quask)",
   "language": "python",
   "name": "qml-quask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
