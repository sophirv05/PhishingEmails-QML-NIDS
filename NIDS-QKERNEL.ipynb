{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e3e8c7",
   "metadata": {},
   "source": [
    "# Detecting network intrusions & anomalies with higher-order topological kernels via quantum computation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9835364-8a41-4eba-8592-9d11c44474e9",
   "metadata": {},
   "source": [
    "## 0. Imports and Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec175ffc",
   "metadata": {},
   "source": [
    "0.0. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e184aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dr.ivanramirez/.pyenv/versions/qml-quask/lib/python3.11/site-packages/pennylane/__init__.py:21: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from quask.core_implementation.qiskit_kernel import QiskitKernel\n",
    "from quask.core import KernelType, Ansatz, KernelFactory\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler   # added\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcc566",
   "metadata": {},
   "source": [
    "0.1. Establish creds if running on IBM hardware (assumes IBM Quantum Cloud account exists and credentials saved with save_account())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0261e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Qiskit simulator (noiseless mode).\n"
     ]
    }
   ],
   "source": [
    "# service = QiskitRuntimeService(instance=\"crn:v1:bluemix:public:quantum-computing:us-east:a/b8ff6077c08a4ea9871560ccb827d457:d3452110-b228-4c79-8959-15ea8cfd435d::\") # assuming creds saved with save_account()\n",
    "# backend = service.backend(\"ibm_rensselaer\")\n",
    "print(\"Running on Qiskit simulator (noiseless mode).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531b83e-8e47-4e0a-84fe-7756a8b6fa04",
   "metadata": {},
   "source": [
    "## 1. Quantum Backend Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca7ad0-b13c-41f5-abe5-018158701a82",
   "metadata": {},
   "source": [
    "### 1.1. Configure for either quantum simulator or hardware backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e690ed",
   "metadata": {},
   "source": [
    "Simulator (noiseless) backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffc0157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelFactory set to Qiskit noiseless simulator.\n"
     ]
    }
   ],
   "source": [
    "def create_qiskit_noiseless(ansatz, measurement: str, type: KernelType):\n",
    "    return QiskitKernel(\n",
    "        ansatz,\n",
    "        measurement,\n",
    "        type,\n",
    "        platform=\"Aer\",\n",
    "        n_shots=None\n",
    "    )\n",
    "\n",
    "try:\n",
    "    KernelFactory.add_implementation('qiskit_noiseless', create_qiskit_noiseless)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "KernelFactory.set_current_implementation('qiskit_noiseless')\n",
    "print(\"KernelFactory set to Qiskit noiseless simulator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f6828",
   "metadata": {},
   "source": [
    "Hardware (NISQ) backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af2a7e",
   "metadata": {},
   "source": [
    "Note: only one implementation can be selected (e.g., qiskit_noiseless OR qiskit_ibm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508d2f8-deaa-4f95-a78e-1b9d3f0a8827",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f988f2-a76a-4c0e-847f-8b73dd3d0ef0",
   "metadata": {},
   "source": [
    "### 2.1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0733b3-0b99-447e-b30e-772670dbf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded datasets: (500, 5) (500, 5)\n"
     ]
    }
   ],
   "source": [
    "benign_path = \"500-benign.npy\"\n",
    "attack_path = \"500-attack.npy\"\n",
    "\n",
    "qX1 = np.load(benign_path)\n",
    "qX2 = np.load(attack_path)\n",
    "\n",
    "attack_name = os.path.basename(attack_path).replace(\"attack\", \"\").replace(\".npy\", \"\").upper()\n",
    "\n",
    "print(\"âœ… Loaded datasets:\", qX1.shape, qX2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0b0fc-dcef-4bb0-be42-bcbfd2f9ab41",
   "metadata": {},
   "source": [
    "### 2.2. Feature Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87f6ea8-ef23-4c22-a6a4-519775d1f3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Number of features: 5\n"
     ]
    }
   ],
   "source": [
    "n_features = qX1.shape[1]\n",
    "print(\"âœ… Number of features:\", n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63115fb7-70e8-49aa-a997-5f6bfdc9e742",
   "metadata": {},
   "source": [
    "### 2.3 Train/Test Split and Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24d0706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data split.\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "\n",
    "qX1 = qX1[:N]\n",
    "qX2 = qX2[:N]\n",
    "\n",
    "qX = np.vstack([qX1, qX2])\n",
    "qy = np.array([-1]*len(qX1) + [1]*len(qX2))\n",
    "\n",
    "qX_train, qX_test, qy_train, qy_test = train_test_split(\n",
    "    qX, qy, test_size=0.3, random_state=42, stratify=qy   # âœ… ADDED stratify\n",
    ")\n",
    "\n",
    "print(\"âœ… Data split.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5894d-0d30-4605-971d-0f4010b35104",
   "metadata": {},
   "source": [
    "### 2.4 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650d1e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data standardized.\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()   # âœ… CHANGED\n",
    "samples = np.append(qX_train, qX_test, axis=0)\n",
    "scaler.fit(samples)\n",
    "\n",
    "qX_train = scaler.transform(qX_train)\n",
    "qX_test = scaler.transform(qX_test)\n",
    "\n",
    "print(\"âœ… Data standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d279e4d-76c4-4eaf-ab55-ff2b74544045",
   "metadata": {},
   "source": [
    "## 3. Quantum Kernel Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e199b8-023d-4c8d-ba2b-7789fa0b8f69",
   "metadata": {},
   "source": [
    "### 3.1 Define Quantum Ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1f803",
   "metadata": {},
   "source": [
    "Config modified from QuASK iris dataset anomaly detection example; see [QuASK: How to optimize a quantum kernel](https://quask.readthedocs.io/en/latest/tutorials_quask/quask_2_optimizers.html) for alternate optimization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7aa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = Ansatz(n_features=n_features, n_qubits=4, n_operations=5)\n",
    "ansatz.initialize_to_identity()\n",
    "\n",
    "ansatz.change_operation(0, 0, [0,1], \"XX\", 2.0)\n",
    "ansatz.change_operation(1, 1, [1,2], \"XY\", 2.0)\n",
    "ansatz.change_operation(2, 2, [2,3], \"XZ\", 2.0)\n",
    "ansatz.change_operation(3, 3, [3,0], \"YY\", 2.0)\n",
    "ansatz.change_operation(4, 4, [0,2], \"YZ\", 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae16d22-12eb-43c4-950d-d0ad0fd270df",
   "metadata": {},
   "source": [
    "### 3.2 Build Quantum Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85bf7a7f-b221-4582-bbe9-fb59cd05db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kernel built successfully!\n"
     ]
    }
   ],
   "source": [
    "kernel = KernelFactory.create_kernel(ansatz, \"ZZZZ\", KernelType.FIDELITY)\n",
    "print(\"âœ… Kernel built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b89c9-2840-487c-80fb-340842132007",
   "metadata": {},
   "source": [
    "## 4. Quantum Model â€“ Baseline Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89155d8e-7980-468e-8552-b8f6ee285ca2",
   "metadata": {},
   "source": [
    "### 4.1 Instantiate SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04308dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SVM upgraded.\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='precomputed', C=10, class_weight='balanced')  \n",
    "print(\"âœ… SVM upgraded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180bf0e-1344-4718-bcfc-78d6bb7244b4",
   "metadata": {},
   "source": [
    "### 4.2 Train Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1964c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Baseline model trained.\n"
     ]
    }
   ],
   "source": [
    "K_train = kernel.build_kernel(qX_train, qX_train)\n",
    "model.fit(K_train, qy_train)\n",
    "print(\"âœ… Baseline model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f7ddc-c9d3-4c76-94c4-36a87eaf203f",
   "metadata": {},
   "source": [
    "### 4.3 Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2a8d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ BASELINE ACCURACY: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "K_test = kernel.build_kernel(qX_test, qX_train)\n",
    "y_pred = model.predict(K_test)\n",
    "\n",
    "baseline_acc = np.mean(qy_test == y_pred)\n",
    "print(\"ðŸŽ¯ BASELINE ACCURACY:\", baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd4568-158d-4098-8444-6faf0bb653cf",
   "metadata": {},
   "source": [
    "## 5. Per-Attack Quantum Evaluation (All Matching .npy Pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d3fbc",
   "metadata": {},
   "source": [
    "The above demo handles a singular network attack, split for improved readability. Below is our testing across all attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b609b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš¨ Evaluating attack: -\n",
      "âœ… Accuracy for -: 0.633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_dir = '.'\n",
    "\n",
    "for fname in os.listdir(data_dir):\n",
    "    if fname.endswith('.npy') and 'benign' in fname:\n",
    "        benign_path = os.path.join(data_dir, fname)\n",
    "        attack_fname = fname.replace('benign', 'attack')\n",
    "        attack_path = os.path.join(data_dir, attack_fname)\n",
    "\n",
    "        attack_label = attack_fname.replace(\"attack\", \"\").replace(\"500\", \"\").replace(\".npy\", \"\").upper()\n",
    "\n",
    "        if os.path.exists(attack_path):\n",
    "\n",
    "            print(f\"\\nðŸš¨ Evaluating attack: {attack_label}\")\n",
    "\n",
    "            # Load data\n",
    "            qX1 = np.load(benign_path)[:50]\n",
    "            qX2 = np.load(attack_path)[:50]\n",
    "\n",
    "            qX = np.vstack([qX1, qX2])\n",
    "            qy = np.array([-1]*len(qX1) + [1]*len(qX2))\n",
    "\n",
    "            # âœ… KEEP CLASS BALANCE\n",
    "            qX_train, qX_test, qy_train, qy_test = train_test_split(\n",
    "                qX, qy,\n",
    "                test_size=0.3,\n",
    "                random_state=42,\n",
    "                stratify=qy\n",
    "            )\n",
    "\n",
    "            # âœ… USE STRONG NORMALIZATION\n",
    "            scaler = StandardScaler()\n",
    "            samples = np.append(qX_train, qX_test, axis=0)\n",
    "            scaler.fit(samples)\n",
    "\n",
    "            qX_train = scaler.transform(qX_train)\n",
    "            qX_test  = scaler.transform(qX_test)\n",
    "\n",
    "            # âœ… TRAIN\n",
    "            K_train = kernel.build_kernel(qX_train, qX_train)\n",
    "            model.fit(K_train, qy_train)\n",
    "\n",
    "            # âœ… TEST\n",
    "            K_test = kernel.build_kernel(qX_test, qX_train)\n",
    "            y_pred = model.predict(K_test)\n",
    "\n",
    "            accuracy = np.mean(qy_test == y_pred)\n",
    "\n",
    "            print(f\"âœ… Accuracy for {attack_label}: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75877fc1-ed41-498b-abfa-3b6bffb31583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ BASELINE ACCURACY: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel=\"precomputed\")\n",
    "\n",
    "K_train = kernel.build_kernel(qX_train, qX_train)\n",
    "model.fit(K_train, qy_train)\n",
    "\n",
    "K_test = kernel.build_kernel(qX_test, qX_train)\n",
    "y_pred = model.predict(K_test)\n",
    "\n",
    "baseline = np.mean(y_pred == qy_test)\n",
    "print(\"ðŸŽ¯ BASELINE ACCURACY:\", baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a308ca-b6db-461c-9991-86a6dfaddc50",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Optimization â€“ SVM C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6125e-2546-4a00-a9dd-228762a4b7ec",
   "metadata": {},
   "source": [
    "### 6.1 Grid Search Over C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96ead0b-253c-498f-b76b-0c60183e1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Tuning SVM parameter C...\n",
      "\n",
      "C =   0.01 â†’ Accuracy = 0.6667\n",
      "C =    0.1 â†’ Accuracy = 0.6667\n",
      "C =      1 â†’ Accuracy = 0.6667\n",
      "C =     10 â†’ Accuracy = 0.6333\n",
      "C =    100 â†’ Accuracy = 0.7333\n",
      "\n",
      "âœ… BEST C: 100\n",
      "ðŸš€ TUNED ACCURACY: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "best_C = None\n",
    "best_acc = 0\n",
    "\n",
    "print(\"\\nðŸ” Tuning SVM parameter C...\\n\")\n",
    "\n",
    "for C in C_values:\n",
    "    model = SVC(kernel=\"precomputed\", C=C)\n",
    "\n",
    "    K_train = kernel.build_kernel(qX_train, qX_train)\n",
    "    model.fit(K_train, qy_train)\n",
    "\n",
    "    K_test = kernel.build_kernel(qX_test, qX_train)\n",
    "    preds = model.predict(K_test)\n",
    "\n",
    "    acc = np.mean(preds == qy_test)\n",
    "    print(f\"C = {C:>6} â†’ Accuracy = {acc:.4f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_C = C\n",
    "\n",
    "print(\"\\nâœ… BEST C:\", best_C)\n",
    "print(\"ðŸš€ TUNED ACCURACY:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fa0db-8c77-4b3a-bb6e-9b9f6cc496f5",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation â€“ Model Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3361692-3f08-4a7c-bb1e-b505d9427bf3",
   "metadata": {},
   "source": [
    "### 7.1. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e81c9664-2db3-4644-b5ba-8f3a875576c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š 5-fold Cross-validation...\n",
      "\n",
      "âœ… CV MEAN: 0.53\n",
      "âœ… CV STD : 0.10295630140987001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "print(\"\\nðŸ“Š 5-fold Cross-validation...\\n\")\n",
    "\n",
    "for train_idx, test_idx in kf.split(qX):\n",
    "    X_tr, X_te = qX[train_idx], qX[test_idx]\n",
    "    y_tr, y_te = qy[train_idx], qy[test_idx]\n",
    "\n",
    "    X_tr = scaler.transform(X_tr)\n",
    "    X_te = scaler.transform(X_te)\n",
    "\n",
    "    K_tr = kernel.build_kernel(X_tr, X_tr)\n",
    "    K_te = kernel.build_kernel(X_te, X_tr)\n",
    "\n",
    "    model = SVC(kernel=\"precomputed\", C=best_C)\n",
    "    model.fit(K_tr, y_tr)\n",
    "    preds = model.predict(K_te)\n",
    "\n",
    "    cv_scores.append(np.mean(preds == y_te))\n",
    "\n",
    "print(\"âœ… CV MEAN:\", np.mean(cv_scores))\n",
    "print(\"âœ… CV STD :\", np.std(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a81e01-d6fc-4437-8de2-d59c0c0f0033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qml-quask)",
   "language": "python",
   "name": "qml-quask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
